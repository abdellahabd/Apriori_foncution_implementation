{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be584e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as  pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546598a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "d=pd.read_csv(\"./Medicaid1986.csv\")\n",
    "d.drop([\"health1\",\"health2\"], axis=1, inplace=True)\n",
    "d.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830920ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = {\n",
    "    'visits': [-1, 1, 6, 10, float('inf')],\n",
    "    'exposure': [0, 30, 60, 90, 120, float('inf')],\n",
    "    'children': [-1, 0, 1, 2, 3, float('inf')],\n",
    "    'age': [0, 18, 30, 50, 70, float('inf')],\n",
    "    'income': [-1, 30, 50, 70, 90, float('inf')],\n",
    "    'access': [ 0, 1, float('inf')],\n",
    "\n",
    "}\n",
    "\n",
    "labels = {\n",
    "    'visits': ['0-1', 'between 2 and 6', 'between 7 and 10', '10+'],\n",
    "    'exposure': ['0-30', '31-60', '61-90', '91-120', '120+'],\n",
    "    'children': ['None', 'One', 'Two', 'Three', 'Four or more'],\n",
    "    'age': ['Child', 'Young_Adult', 'Adult', 'Middle-Aged', 'Senior'],\n",
    "    'income': ['Low', 'Lower_Middle', 'Middle', 'Upper_Middle', 'High'],\n",
    "    'access': ['Low_Access', 'High_Access'],\n",
    "\n",
    "}\n",
    "\n",
    "for feature in bins.keys():\n",
    "    d[feature + '_category'] = pd.cut(d[feature], bins=bins[feature], labels=labels[feature])\n",
    "\n",
    "d.drop(list(bins.keys()), axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c13eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "d.drop([\"school\",\"rownames\"], axis=1, inplace=True)\n",
    "d.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1208d937",
   "metadata": {},
   "outputs": [],
   "source": [
    "d.to_csv(\"test2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34c0f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "ap=pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173d3730",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in d.columns:\n",
    "    uniqitems=d[col].unique()\n",
    "    for uniq in uniqitems:    \n",
    "        ap[col+\"_\"+str(uniq)]= [1 if (str(value) == str(uniq)) else 0 for value in d[col]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4139908",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ap.to_csv(\"test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c889738",
   "metadata": {},
   "outputs": [],
   "source": [
    "ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3135aa01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# minSup= 498/996\n",
    "\n",
    "def L1(ap,minSup):\n",
    "    my_series=ap.sum(axis=0)\n",
    "    l1=my_series[my_series > minSup]\n",
    "    print(l1)\n",
    "    print(len(l1))\n",
    "    return l1,l1.index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3eb9d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 , nw_col =L1(ap,498)\n",
    "new_ap =ap[nw_col]\n",
    "new_ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38d6425",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ItemSet(itemSet_p,Minsup,data):\n",
    "    list1=[]\n",
    "    list2=[]\n",
    "    for index, col1 in enumerate(itemSet_p.index[:-1]):\n",
    "        for ind, col2 in enumerate(itemSet_p.index[index+1:]):\n",
    "            if(col1.rsplit(\"+\",1)[0]==col2.rsplit(\"+\",1)[0]):\n",
    "                new_col=col1 +\"+\"+ col2.rsplit(\"+\",1)[-1]\n",
    "                list1.append(new_col) \n",
    "                columns=new_col.split(\"+\")\n",
    "                condition = (data[columns[0]] == 1)\n",
    "                for i in (columns[1:]):\n",
    "                    condition &= (data[i] == 1)\n",
    "                list2.append(len(data[condition]))\n",
    "                \n",
    "    new_SR=pd.Series(data=list2,\n",
    "    index=list1)\n",
    "    new_SR=new_SR[new_SR > Minsup]\n",
    "\n",
    "    return new_SR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f03739",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Apriori(Minsup,data):\n",
    "    my_series=ap.sum(axis=0)\n",
    "    sr=my_series[my_series > Minsup]\n",
    "    disct={\"1_itemsets\":sr}\n",
    "    print(\"1_itemsets\")\n",
    "    print(l1)\n",
    "    print(len(l1))\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    list1=[]\n",
    "    list2=[]\n",
    "    \n",
    "    for index, col in enumerate(sr.index[:-1]):\n",
    "        for ind, col2 in enumerate(data.columns[index+1:]):\n",
    "            list1.append(col + \"+\" + col2 )\n",
    "            list2.append( len(data[(data[col] == 1) & (data[col2] == 1)]))\n",
    "\n",
    "    sr=pd.Series(data=list2,\n",
    "        index=list1)\n",
    "    sr=sr[sr > Minsup]\n",
    "    sr1=sr\n",
    "    niveau=2\n",
    "\n",
    "    while(len(sr1)!=0):\n",
    "        print(f\"{niveau}_itemsets\")\n",
    "        print(sr1)\n",
    "        print(len(sr1))\n",
    "        print(\"\\n\")\n",
    "        disct[f\"{niveau}_itemsets\"]=sr1\n",
    "        sr1=ItemSet(sr1,Minsup,data)\n",
    "        niveau+=1\n",
    "\n",
    "    return disct\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "#l'idea est change le minsup minf----minsup----maxf ====> s9si ismail (decotomique)\n",
    "#3la ap ji kter mn new_ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b773e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "dic =Apriori(498,new_ap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da8e16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "def sup(item_set):\n",
    "    \"\"\"\n",
    "    jib sup in dictionary dic\n",
    "    \"\"\"\n",
    "    key=f\"{len(item_set.split('+'))}_itemsets\"\n",
    "\n",
    "    return dic[key][item_set] \n",
    "\n",
    "def construire_regles(Item_set):\n",
    "    Confiance=[] \n",
    "    regles = []\n",
    "    items = Item_set.split(\"+\")\n",
    "    for r in range(1, len(items)):\n",
    "        for comb in combinations(items, r):\n",
    "            left = \"+\".join(list(comb))\n",
    "            right = \"+\".join([item for item in items if item not in comb])\n",
    "            regles.append(left + \"->\" + right)\n",
    "            # ////\n",
    "            sup_Antecedant=sup(Item_set)\n",
    "            sup_Consequent=sup(left)\n",
    "            Confiance.append(sup_Antecedant/sup_Consequent)\n",
    "\n",
    "            \n",
    "    return regles,Confiance\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02def03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "regle=[]\n",
    "Concfiance=[]\n",
    "\n",
    "for key in list(dic.keys())[1:]:\n",
    "    for itemset in dic[key].index:\n",
    "        regles,Concfiances= construire_regles(itemset)\n",
    "\n",
    "        regle=regle+regles\n",
    "        Concfiance=Concfiance+Concfiances\n",
    "\n",
    "SR=pd.Series(Concfiance, index=regle)\n",
    "SR=SR[SR>=0.65]\n",
    "SR.name=\"Concfiance\"\n",
    "SR.index.name=\"Règles d'association\"\n",
    "SR.to_csv(\"Regles.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4291d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pour l'optimistaion\n",
    "\"\"\"\n",
    "from multiprocessing import Pool\n",
    "from joblib import Parallel, delayed\n",
    "import dask\n",
    "\n",
    "# 1- Calcul du support\n",
    "def calculate_support(itemset):\n",
    "    # Insérez ici le code pour calculer le support d'un itemset\n",
    "    pass\n",
    "\n",
    "with Pool() as p:\n",
    "    supports = p.map(calculate_support, itemsets)\n",
    "\n",
    "# 2- Génération des règles d'association\n",
    "def generate_association_rules(itemset):\n",
    "    # Insérez ici le code pour générer les règles d'association d'un itemset\n",
    "    pass\n",
    "\n",
    "association_rules = Parallel(n_jobs=-1)(delayed(generate_association_rules)(itemset) for itemset in itemsets)\n",
    "\n",
    "# 3- Calcul de la confiance\n",
    "def calculate_confidence(rule):\n",
    "    # Insérez ici le code pour calculer la confiance d'une règle d'association\n",
    "    pass\n",
    "\n",
    "confidence_values = dask.compute(*[dask.delayed(calculate_confidence)(rule) for rule in association_rules])\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
